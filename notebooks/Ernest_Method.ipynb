{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>k_mer</th>\n",
       "      <th>left_dwell</th>\n",
       "      <th>left_std</th>\n",
       "      <th>left_mean</th>\n",
       "      <th>mid_dwell</th>\n",
       "      <th>mid_std</th>\n",
       "      <th>mid_mean</th>\n",
       "      <th>right_dwell</th>\n",
       "      <th>right_std</th>\n",
       "      <th>right_mean</th>\n",
       "      <th>label</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>R</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2.060</td>\n",
       "      <td>125.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>10.400</td>\n",
       "      <td>122.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>10.900</td>\n",
       "      <td>84.100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.530</td>\n",
       "      <td>125.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>4.670</td>\n",
       "      <td>126.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6.300</td>\n",
       "      <td>80.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.920</td>\n",
       "      <td>109.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>12.000</td>\n",
       "      <td>124.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.130</td>\n",
       "      <td>79.600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2.060</td>\n",
       "      <td>125.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.010</td>\n",
       "      <td>130.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.780</td>\n",
       "      <td>80.400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2.920</td>\n",
       "      <td>120.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3.940</td>\n",
       "      <td>129.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>7.150</td>\n",
       "      <td>82.200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene_id    transcript_id  transcript_position    k_mer  left_dwell  \\\n",
       "0  ENSG00000004059  ENST00000000233                  244  AAGACCA       0.003   \n",
       "1  ENSG00000004059  ENST00000000233                  244  AAGACCA       0.006   \n",
       "2  ENSG00000004059  ENST00000000233                  244  AAGACCA       0.005   \n",
       "3  ENSG00000004059  ENST00000000233                  244  AAGACCA       0.004   \n",
       "4  ENSG00000004059  ENST00000000233                  244  AAGACCA       0.007   \n",
       "\n",
       "   left_std  left_mean  mid_dwell  mid_std  mid_mean  right_dwell  right_std  \\\n",
       "0     2.060    125.000      0.018   10.400   122.000        0.009     10.900   \n",
       "1     2.530    125.000      0.008    4.670   126.000        0.010      6.300   \n",
       "2     3.920    109.000      0.014   12.000   124.000        0.005      2.130   \n",
       "3     2.060    125.000      0.008    5.010   130.000        0.005      3.780   \n",
       "4     2.920    120.000      0.003    3.940   129.000        0.013      7.150   \n",
       "\n",
       "   right_mean  label  D1  D2  R  H1  H2  \n",
       "0      84.100      0   1   0  0   0   1  \n",
       "1      80.900      0   1   0  0   0   1  \n",
       "2      79.600      0   1   0  0   0   1  \n",
       "3      80.400      0   1   0  0   0   1  \n",
       "4      82.200      0   1   0  0   0   1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "DATA_PATH = \"../data/raw/dataset.csv\"\n",
    "\n",
    "data = pd.read_csv(DATA_PATH).iloc[:, 1:] # exclude the first column as it is the index\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           gene_id  left_dwell  left_std  left_mean  mid_dwell  mid_std  \\\n",
      "0  ENSG00000004059       0.003     2.060    125.000      0.018   10.400   \n",
      "1  ENSG00000004059       0.006     2.530    125.000      0.008    4.670   \n",
      "2  ENSG00000004059       0.005     3.920    109.000      0.014   12.000   \n",
      "3  ENSG00000004059       0.004     2.060    125.000      0.008    5.010   \n",
      "4  ENSG00000004059       0.007     2.920    120.000      0.003    3.940   \n",
      "\n",
      "   mid_mean  right_dwell  right_std  right_mean  label  \n",
      "0   122.000        0.009     10.900      84.100      0  \n",
      "1   126.000        0.010      6.300      80.900      0  \n",
      "2   124.000        0.005      2.130      79.600      0  \n",
      "3   130.000        0.005      3.780      80.400      0  \n",
      "4   129.000        0.013      7.150      82.200      0  \n"
     ]
    }
   ],
   "source": [
    "# Selecting specific columns\n",
    "selected_columns = [\n",
    "    \"gene_id\", 'left_dwell', 'left_std', 'left_mean',\n",
    "    'mid_dwell', 'mid_std', 'mid_mean',\n",
    "    'right_dwell', 'right_std', 'right_mean', 'label'\n",
    "]\n",
    "result_df = data[selected_columns]\n",
    "\n",
    "print(result_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Define the size of your encoded representations\n",
    "encoding_dim = 32  # Adjust as needed\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "# Replace this with your dataset loading and preprocessing code\n",
    "# Make sure you have 'x_data' as your input features and 'y_labels' as your labels\n",
    "\n",
    "# Filter your data to keep only label 0\n",
    "# x_data_label_0 = x_data[y_labels == 0]\n",
    "x_data_label_0 = result_df[result_df['label'] == 0].drop(columns=['label'])\n",
    "\n",
    "# Define the input shape based on your feature dimensionality\n",
    "input_shape = (9,)  # Adjust to match your data\n",
    "\n",
    "# Create the input layer\n",
    "input_img = keras.Input(shape=input_shape)\n",
    "\n",
    "# Define the architecture of the autoencoder\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = layers.Dense(input_shape[0], activation='sigmoid')(encoded)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "\n",
    "# Create the encoder model\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "\n",
    "# Create the decoder model\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder using only the samples with label 0\n",
    "autoencoder.fit(x_data_label_0, x_data_label_0,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2)  # You can use a validation split\n",
    "\n",
    "# Encode and decode the data\n",
    "encoded_data = encoder.predict(result_df)  # Encode all data\n",
    "decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# Calculate the similarity between original and reconstructed data\n",
    "# You can use a suitable similarity metric (e.g., mean squared error)\n",
    "similarity = np.mean(np.square(result_df - decoded_data), axis=1)\n",
    "\n",
    "# Set a similarity threshold (you can adjust this value)\n",
    "threshold = 0.1\n",
    "\n",
    "# Assign labels based on the similarity threshold\n",
    "predicted_labels = [1 if sim > threshold else 0 for sim in similarity]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define the size of your encoded representations\n",
    "encoding_dim = 3  # Adjust as needed\n",
    "\n",
    "# Filter your data to keep only label 0\n",
    "x_data_label_0 = result_df[result_df['label'] == 0].drop(columns=['label'])\n",
    "\n",
    "# Initialize the Min-Max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform\n",
    "x_data_label_0_scaled = scaler.fit_transform(x_data_label_0)\n",
    "\n",
    "# Define the input shape based on your feature dimensionality\n",
    "input_shape = (x_data_label_0_scaled.shape[1],)  # This will be (9,)\n",
    "\n",
    "# Create the input layer\n",
    "input_img = keras.Input(shape=input_shape)\n",
    "\n",
    "# Define the architecture of the autoencoder\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = layers.Dense(input_shape[0], activation='sigmoid')(encoded)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "\n",
    "# Create the encoder model\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "\n",
    "# Create the decoder model\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder using the scaled data\n",
    "autoencoder.fit(x_data_label_0_scaled, x_data_label_0_scaled,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2)  # You can use a validation split\n",
    "\n",
    "# To encode and decode, make sure to scale the input data first\n",
    "result_df_scaled = scaler.transform(result_df.drop(columns=['label']))\n",
    "\n",
    "# Encode and decode the scaled data\n",
    "encoded_data = encoder.predict(result_df_scaled)\n",
    "decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# You might want to inverse transform the decoded data if you're going to calculate similarity with original data\n",
    "decoded_data_inverse_transformed = scaler.inverse_transform(decoded_data)\n",
    "\n",
    "# Calculate the similarity between original and reconstructed data\n",
    "similarity = np.mean(np.square(result_df.drop(columns=['label']) - decoded_data_inverse_transformed), axis=1)\n",
    "\n",
    "# Set a similarity threshold (you can adjust this value)\n",
    "threshold = 0.1\n",
    "\n",
    "# Assign labels based on the similarity threshold\n",
    "predicted_labels = [1 if sim > threshold else 0 for sim in similarity]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24400/24400 [==============================] - 58s 2ms/step - loss: 0.3151 - val_loss: 0.3096\n",
      "Epoch 2/5\n",
      "24400/24400 [==============================] - 55s 2ms/step - loss: 0.3091 - val_loss: 0.3096\n",
      "Epoch 3/5\n",
      "24400/24400 [==============================] - 57s 2ms/step - loss: 0.3091 - val_loss: 0.3096\n",
      "Epoch 4/5\n",
      "24400/24400 [==============================] - 57s 2ms/step - loss: 0.3091 - val_loss: 0.3096\n",
      "Epoch 5/5\n",
      "24400/24400 [==============================] - 58s 2ms/step - loss: 0.3091 - val_loss: 0.3096\n",
      "63212/63212 [==============================] - 84s 1ms/step\n",
      "63212/63212 [==============================] - 79s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the size of your encoded representations\n",
    "encoding_dim = 3  # Adjust as needed\n",
    "\n",
    "# Filter your data to keep only label 0\n",
    "x_data_label_0 = result_df[result_df['label'] == 0].drop(columns=['label'])\n",
    "\n",
    "# Get unique gene_id values\n",
    "unique_genes = result_df['gene_id'].unique()\n",
    "\n",
    "# Shuffle the unique gene_ids\n",
    "np.random.shuffle(unique_genes)\n",
    "\n",
    "# Split unique gene_ids into train, validation, and test\n",
    "train_size = int(0.6 * len(unique_genes))\n",
    "val_size = int(0.2 * len(unique_genes))\n",
    "train_genes = unique_genes[:train_size]\n",
    "val_genes = unique_genes[train_size:train_size + val_size]\n",
    "test_genes = unique_genes[train_size + val_size:]\n",
    "\n",
    "# Create train, validation, and test dataframes based on the split gene_ids\n",
    "train_df = x_data_label_0[x_data_label_0['gene_id'].isin(train_genes)]\n",
    "val_df = x_data_label_0[x_data_label_0['gene_id'].isin(val_genes)]\n",
    "test_df = x_data_label_0[x_data_label_0['gene_id'].isin(test_genes)]\n",
    "\n",
    "# Initialize the Min-Max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Exclude gene_id for scaling\n",
    "features_to_scale = train_df.drop(columns=['gene_id'])\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "train_df_scaled = scaler.fit_transform(features_to_scale)\n",
    "\n",
    "# For the validation set, also exclude gene_id before scaling\n",
    "val_features_to_scale = val_df.drop(columns=['gene_id'])\n",
    "val_df_scaled = scaler.transform(val_features_to_scale)\n",
    "\n",
    "# Define the input shape based on your feature dimensionality\n",
    "input_shape = (train_df_scaled.shape[1],)  # This will be (10,)\n",
    "\n",
    "# Create the input layer\n",
    "input_img = keras.Input(shape=input_shape)\n",
    "\n",
    "# Define the architecture of the autoencoder\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = layers.Dense(input_shape[0], activation='sigmoid')(encoded)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "\n",
    "# Create the encoder model\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "\n",
    "# Create the decoder model\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder using the scaled data\n",
    "autoencoder.fit(train_df_scaled, train_df_scaled,\n",
    "                epochs=5,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(val_df_scaled, val_df_scaled))\n",
    "\n",
    "# To encode and decode, use the test set\n",
    "test_features_to_scale = test_df.drop(columns=['gene_id'])\n",
    "test_df_scaled = scaler.transform(test_features_to_scale)\n",
    "\n",
    "\n",
    "# Encode and decode the scaled test data\n",
    "encoded_data = encoder.predict(test_df_scaled)\n",
    "decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# You might want to inverse transform the decoded data if you're going to calculate similarity with original data\n",
    "decoded_data_inverse_transformed = scaler.inverse_transform(decoded_data)\n",
    "\n",
    "# Calculate the similarity between original and reconstructed test data\n",
    "similarity = np.mean(np.square(test_features_to_scale - decoded_data_inverse_transformed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25025/25025 [==============================] - 94s 4ms/step - loss: 0.3197 - val_loss: 0.3155\n",
      "Epoch 2/5\n",
      "25025/25025 [==============================] - 79s 3ms/step - loss: 0.3145 - val_loss: 0.3142\n",
      "Epoch 3/5\n",
      "25025/25025 [==============================] - 113s 5ms/step - loss: 0.3129 - val_loss: 0.3122\n",
      "Epoch 4/5\n",
      "25025/25025 [==============================] - 93s 4ms/step - loss: 0.3116 - val_loss: 0.3119\n",
      "Epoch 5/5\n",
      "25025/25025 [==============================] - 90s 4ms/step - loss: 0.3115 - val_loss: 0.3118\n",
      "65878/65878 [==============================] - 120s 2ms/step\n",
      "65878/65878 [==============================] - 98s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the size of your encoded representations\n",
    "encoding_dim = 3  # Adjust as needed\n",
    "\n",
    "# Filter your data to keep only label 0\n",
    "x_data_label_0 = result_df[result_df['label'] == 0].drop(columns=['label'])\n",
    "\n",
    "# Get unique gene_id values\n",
    "unique_genes = result_df['gene_id'].unique()\n",
    "\n",
    "# Shuffle the unique gene_ids\n",
    "np.random.shuffle(unique_genes)\n",
    "\n",
    "# Split unique gene_ids into train, validation, and test\n",
    "train_size = int(0.6 * len(unique_genes))\n",
    "val_size = int(0.2 * len(unique_genes))\n",
    "train_genes = unique_genes[:train_size]\n",
    "val_genes = unique_genes[train_size:train_size + val_size]\n",
    "test_genes = unique_genes[train_size + val_size:]\n",
    "\n",
    "# Create train, validation, and test dataframes based on the split gene_ids\n",
    "train_df = x_data_label_0[x_data_label_0['gene_id'].isin(train_genes)]\n",
    "val_df = x_data_label_0[x_data_label_0['gene_id'].isin(val_genes)]\n",
    "test_df = x_data_label_0[x_data_label_0['gene_id'].isin(test_genes)]\n",
    "\n",
    "# Initialize the Min-Max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Exclude gene_id for scaling\n",
    "features_to_scale = train_df.drop(columns=['gene_id'])\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "train_df_scaled = scaler.fit_transform(features_to_scale)\n",
    "\n",
    "# For the validation set, also exclude gene_id before scaling\n",
    "val_features_to_scale = val_df.drop(columns=['gene_id'])\n",
    "val_df_scaled = scaler.transform(val_features_to_scale)\n",
    "\n",
    "# Define the input shape based on your feature dimensionality\n",
    "input_shape = (train_df_scaled.shape[1],)  # This will depend on your data\n",
    "\n",
    "# Create the input layer\n",
    "input_img = keras.Input(shape=input_shape)\n",
    "\n",
    "# Define the architecture of the autoencoder\n",
    "# First hidden layer\n",
    "hidden1_size = 64  # Hyperparameter: number of neurons in the first hidden layer\n",
    "hidden1 = layers.Dense(hidden1_size, activation='relu')(input_img)\n",
    "\n",
    "# Second hidden layer (encoded layer)\n",
    "# You can adjust 'encoding_dim' as a hyperparameter to fine-tune the size of the bottleneck layer\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(hidden1)\n",
    "\n",
    "# Third hidden layer (decoder starts here)\n",
    "hidden2_size = hidden1_size  # You can set this to another value if desired\n",
    "hidden2 = layers.Dense(hidden2_size, activation='relu')(encoded)\n",
    "\n",
    "# Output layer\n",
    "decoded = layers.Dense(input_shape[0], activation='sigmoid')(hidden2)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "\n",
    "# Create the encoder model\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "\n",
    "# Create the decoder model\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "decoder_layers = autoencoder.layers[-2](encoded_input)  # Use third hidden layer\n",
    "decoder_output = autoencoder.layers[-1](decoder_layers)  # Use output layer\n",
    "decoder = keras.Model(encoded_input, decoder_output)\n",
    "\n",
    "# Hyperparameters: You can adjust the optimizer type, learning rate, and loss function as needed\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder using the scaled data\n",
    "# Hyperparameters: You can adjust the number of epochs and batch size\n",
    "autoencoder.fit(train_df_scaled, train_df_scaled,\n",
    "                epochs=5,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(val_df_scaled, val_df_scaled))\n",
    "\n",
    "# To encode and decode, use the test set\n",
    "test_features_to_scale = test_df.drop(columns=['gene_id'])\n",
    "test_df_scaled = scaler.transform(test_features_to_scale)\n",
    "\n",
    "\n",
    "# Encode and decode the scaled test data\n",
    "encoded_data = encoder.predict(test_df_scaled)\n",
    "decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "# You might want to inverse transform the decoded data if you're going to calculate similarity with original data\n",
    "decoded_data_inverse_transformed = scaler.inverse_transform(decoded_data)\n",
    "\n",
    "# Calculate the similarity between original and reconstructed test data\n",
    "similarity = np.mean(np.square(test_features_to_scale - decoded_data_inverse_transformed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40416      12.798\n",
       "40417       2.828\n",
       "40418       3.194\n",
       "40419       1.338\n",
       "40420       1.817\n",
       "            ...  \n",
       "11018356    1.064\n",
       "11018357    3.763\n",
       "11018358    6.559\n",
       "11018359    0.298\n",
       "11018360    0.502\n",
       "Length: 2108084, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Your similarity data (as a list or numpy array for this example)\n",
    "\n",
    "# Reshape the similarity data\n",
    "similarity_reshaped = [[value] for value in similarity]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the similarity values\n",
    "normalized_similarity = scaler.fit_transform(similarity_reshaped)\n",
    "\n",
    "# Flatten the normalized similarity data back to a 1D list\n",
    "normalized_similarity = [value[0] for value in normalized_similarity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.606773176661034e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the 95th percentile\n",
    "percentile_5 = np.percentile(normalized_similarity, 5)\n",
    "\n",
    "print(percentile_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a similarity threshold (you can adjust this value)\n",
    "threshold = percentile_5\n",
    "\n",
    "# Assign labels based on the similarity threshold\n",
    "predicted_labels = [0 if sim > threshold else 1 for sim in normalized_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the PDF\n",
    "sns.kdeplot(normalized_similarity, fill=True)\n",
    "\n",
    "# Adjust x and y axis limits to focus on the bulk of the data\n",
    "plt.xlim(min(normalized_similarity), max(normalized_similarity))\n",
    "plt.ylim(0, 1.2 * max(sns.kdeplot(normalized_similarity, cumulative=False).get_lines()[0].get_data()[1]))\n",
    "\n",
    "plt.xlabel('Normalized Similarity')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Probability Density Function of Normalized Similarity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105405"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499574\n"
     ]
    }
   ],
   "source": [
    "count_label_1 = result_df[result_df['label'] == 1].shape[0]\n",
    "print(count_label_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
